Data를 갖고
훈련용, 평가, 검증용용 데이터로 나누면 되는데,
좋은 훈련 결과를 얻으려면 데이터를 모두 활용하는 것이 좋고
좋은 평가, 검증을 얻으려면 또한 데이터를 모두 활용하는 것이 좋음

# k-fold Cross-Validation
k개의 다양한 훈련, 검증용 데이터 셋을 구분한 세트들을 구성
평가에 활용되는 것을 평균을 냄
그리고 각각 훈련, 및 평가한 것을 평균을 냄

# Leave One Out Cross Validation (LOOCV)
하나의 데이터셋을 제외한 모든 데이터를 훈련용으로 사용
하나는 평가, 검증용으로 사용
역시 여러 데이터 셋을 만듦

문제는 이렇게 접근하면 컴퓨터 리소스 사용량이 크게 증가한다는 것

교차 확인 절차를 거치게 되면 보다 나은, 안정적인 결과를 얻을 수 있고
다른 ML 알고리즘과 비교도 수월해짐
hyperparameter의 tuning 분석도 수월해짐

다만 컴퓨터 활용량이 매우 크게 증가하는 문제가 있음 - 하드웨어 성능이 매우 많이 필요
