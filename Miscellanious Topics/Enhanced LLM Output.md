# Prompt Engineering, RAG, Finetuning
LLM의 출력을 보다 좋게 하기 위한 방법이 어려가지

사용자의 질문을 직접 집어넣으면 > 제대로 응답하지 못하는 경우가 많음
가장 간단히 생각할 수 있는 것이 prompt engineering인데
사용자의 질문을 받아 그 내용을 일부 수정하여 LLM에 전달하는 것

그런데 LLM이 학습하지 않은 그 이후의 내용에 대한 답변이 필요한 경우에는?
RAG기법이 활용됨
외부의 자료 내용을 토대로 LLM에 질문하는 것
외부의 자료는 vector database 혹은 외부의 문서일 수 있음
그런데 이렇게 접근하는 것은 시스템이 조금 더 복잡해지는 부분이 있음
응답이 느릴 수 있는 문제가 있음

Finetuning은 두 단계로 진행
외부 데이터로 LLM을 간단히 훈련시켜 Finetuning된 LLM을 기반으로 사용자의 요청에 답변하게 됨
